my_pois <- replicate(100, rpois(5, 10))
my_pois
colMeans(my_pois)
cm <- colMeans(my_pois)
hist(cm)
library("swirl")
swirl()
data(cars)
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(y = cars$speed, x = cars$dist)
?plot
plot(y = cars$speed, x = cars$dist, xlab = "Speed")
plot(y = cars$speed, x = cars$dist, ylab = "Speed")
plot(y = cars$speed, x = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab="Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab="Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab="Stopping Distance")
plots(cars), main ="My Plot")
plots(cars, main ="My Plot")
plot(cars, main ="My Plot")
plots(cars, sub ="My Plot Subtitle")
plot(cars, sub ="My Plot Subtitle")
plot(cars, col = 2)
plot(cars, xlim = c(10,15))
plot(cars, pch = 2)
mtcars
data("mtcars")
data(mtcars)
?boxplot
boxplot (mpg ~ cyl, mtcars)
hist(mtcars$mpg)
library(swirl)
swirl)()
swirl()
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
?download.file
dt <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
dt <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv","survet.csv")
dt <- read.csv("survet.csv")
summary(dt)
dt$VAL
dt$VAL>1000000
count(dt$VAL>1000000)
sum(dt$VAL>1000000)
dt[dt$VAL>1000000]
dt[dt$VAL>1000000,]
dt[dt$VAL>100000,]
dt[dt$VAL==24,]
dt$VAL==24
dt[dt$VAL==24,]
sum(dt[dt$VAL==24,])
summary(dt$VAL)
sum(dt[dt$VAL==24.00,])
dt[dt$VAL==24.00,]
nrows(dt[dt$VAL==24.00,])
nrow(dt[dt$VAL==24.00,])
nrow(dt)
sum(dt[dt$VAL==24.00, na.rm=T)])
sum(na.omit(dt$VAL)==24.00)
dt <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx ","ngap.xlsx")
dt <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx","ngap.xlsx")
require(xlsx)
install.packages("xlsx")
library("xlsx")
library("xlsx")
install.packages("xlsx")
install.packages("xlsx")
install.packages("xlsx")
library("xlsx")
install.packages("xlsx")
install.packages(“xlsx”)
install.packages("xlsx")
library("xlsx")
?read.xlsx
dat <-read.xlsx((""))
dat <-read.xlsx("ngap.xls",colIndex = 7:15, rowIndex = 18:23)
dat <-read.xlsx("ngap.xls",sheetIndex = 1,colIndex = 7:15, rowIndex = 18:23)
getwd()
dat <-read.xlsx("./ngap.xls",sheetIndex = 1,colIndex = 7:15, rowIndex = 18:23)
dat <-read.xlsx(".\ngap.xls",sheetIndex = 1,colIndex = 7:15, rowIndex = 18:23)
dat <-read.xlsx("ngap.xlsx",sheetIndex = 1,colIndex = 7:15, rowIndex = 18:23)
sum(dat$Zip*dat$Ext,na.rm=T)
dt <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv","survey2.csv")
?fread
DT <- fread("survey2.csv")
library("data.table")
dat <-read.xlsx(".\ngap.xls",sheetIndex = 1,colIndex = 7:15, rowIndex = 18:23)inser
package.install("data.table")
require(data.table)
install.packages("data.table")
DT <- fread("survey2.csv")
library("data.table")
DT <- fread("survey2.csv")
require(XML)
install.packages("XML")
require(XML)
library("XML")
install.packages("XML")
install.packages("XML")
install.packages("XML")
install.packages("XML")
require(XML)
data <- xmlParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
library(RCurl)
xData <- getURL(fileURL)
fileURL <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xData <- getURL(fileURL)
doc <- xmlParse(xData)
summary(doc)
doc <- xmlTreeParse(file=fileURL,useInternal=TRUE)
doc <- xmlTreeParse(file=fileURL,useInternal=TRUE)
doc <- xmlTreeParse(file=fileURL)
doc <- xmlTreeParse(file=fileURL,useInternal=TRUE)
xData <- getURL(fileURL)
doc <- xmlTreeParse(xData,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
rootNode[[1]][[1]]
zipcode <- xpathSApply(rootNode,"//zipcode",xmlValue)
length(zipcode[zipcode==21231])
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "70d9acf41661583d7a77",
secret = "4c18ac33dec10fb1054f85321c190880bf52e7e3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("github",
key = "70d9acf41661583d7a77",
secret = "4c18ac33dec10fb1054f85321c190880bf52e7e3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
closeConnections()
;
closeConnections()
myapp <- oauth_app("github",
key = "70d9acf41661583d7a77",
secret = "4c18ac33dec10fb1054f85321c190880bf52e7e3")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
myapp <- oauth_app("github",
key = "70d9acf41661583d7a77",
secret = "55af26ff0adae4aea63b585e5814296fe017fe83")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
myapp <- oauth_app("github",
key = "70d9acf41661583d7a77",
secret = "244e9ef5d8a7dc88e011162504c98d8ba3352083")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("github",
key = "70d9acf41661583d7a77",
secret = "18d1f5bf5cf703436e8d515094d5854ed2defdc8")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "70d9acf41661583d7a77",
secret = "18d1f5bf5cf703436e8d515094d5854ed2defdc8")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status((req))
stop_for_status(req)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
output
list(output[[4]]$name, output[[4]]$created_at)
list(output[[2]]$name, output[[4]]$created_at)
summary(output)
head(output)
list(output[[4]]$name, output[[4]]$created_at)
xpathrequire(httpuv)
require(jsonlite)
require(httpuv)
require(jsonlite)
xpathApply(content,"//datasharing")
library(XML)
xpathApply(content,"//datasharing")
json = fromJSON(toJSON(jsonTemp))
json = fromJSON(toJSON(content))
json[json$name == "datasharing", "created_at"]
json <- fromJSON(toJSON(content))
json[json$name == "datasharing", "created_at"]
json <- fromJSON(toJSON(output))
json[json$name == "datasharing", "created_at"]
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(con)
close(con)
close(con)
nchar(htmlCode[c(10, 20, 30, 100)])
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n = 10)
d <- read.fwf(url)
wksst <- read.fwf(
file = url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip = 4,
widths = c(12, 7,4, 9,4, 9,4, 9,4))
sum(wksst[, 4])
library(swirl)
swirl()
mydf <- read.csv(path2csv,stringsAsFactors = F)
mydf <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran,
| ip_id, package, country)
select(cran,ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran,-5:20)
X
ls
-5:20
-(5:20)
select(cran,-(5:20))
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, users in (India))
filter(cran, users "IN" (India))
filter(cran, users IN (India))
filter(cran, users "IN" (India))
filter(cran, r_version == "3.1.1", country == "US")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")]
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran,size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version),ip_id)
cran3 <- select(cran, ip_id,package,size)
cran
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_mb = size / 2^20,size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library("swirl")
swirl()
type(dplyr)
library(dplyr)
cran <- tbl_df(mydf)
View(mydf)
View(cran)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,.package)
by_package <- group_by(cran,"package")
by_package <- group_by(cran,package)
by_package
summarize(by_package,mean(size))
?n
?n_distincr
?n_distinct
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
filter(by_package,count > 679)
?filter
filter(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs =
| 0.99)
quantile(pack_sum$unique, probs = 0.99)
filter(pack_sum, unique > 465)
filter(pack_sum, unique > 465)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique,desc(unique))
View(top_unique_sorted)
?summarize
submit()
submit()
submit()
View(results3)
View(result3)
submit()
submit()
submit()
submit()
library("swirl")
swirl()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
res <- gather(students2, sex_class,count,-grade)
res
?seperate
info()
?seprate
?sepArate
?separate
seperate(res,col=sex_class,into = c("sex","class"))
separate(res,col=sex_class,into = c("sex","class"))
submit()
submit()
students3
submit()
?spread
?spread()
submit()
library(readr)
parse_number("class5")
submit()
?mutate
submit()
?parse_number
submit()
submit()
students4
submit()
submit()
submit()
passed
failed
mutate(passed,passed="passed")
passed <- mutate(passed,passed="passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
?bind_rows
bind_rows(passed,failed)
sat
?select
submit()
submit()
library(jpeg)
library(data.table)
library(dplyr)
library(jpeg)
library(dplyr)
library(data.table)
library(Hmisc)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
f <- file.path(getwd(), "ss06hid.csv")
download.file(url, f)
dt <- data.table(read.csv(f))
agricultureLogical <- dt$ACR == 3 & dt$AGS == 6
which(agricultureLogical)[1:3]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
f <- file.path(getwd(), "jeff.jpg")
download.file(url, f, mode="wb")
g <- readJPEG(f, native=TRUE)
package.install("jpeg")
install.packages("jpeg")
library(jpeg)
g <- readJPEG(f, native=TRUE)
quantile(g, probs=c(0.3, 0.8))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip=4, nrows=215))
dtGDP
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "gdp"))
dtGDP
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
f <- file.path(getwd(), "EDSTATS_Country.csv")
download.file(url, f)
dtEd <- data.table(read.csv(f))
dt <- merge(dtGDP, dtEd, all=TRUE, by=c("CountryCode"))
dt
sum(!is.na(unique(dt$rankingGDP)))
dt[order(rankingGDP, decreasing=TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, gdp)][13]
dt[order(rankingGDP, decreasing=TRUE),][13]
dt[order(rankingGDP, decreasing=TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, gdp)][13]
tapply(merge$Rank, merge$`Income Group`, mean)
tapply(dt$Rank, dt$`Income Group`, mean)
dt[, mean(rankingGDP, na.rm=TRUE), by=Income.Group]
breaks <- quantile(dt$rankingGDP, probs=seq(0, 1, 0.2), na.rm=TRUE)
breaks
dt$quantileGDP <- cut(dt$rankingGDP, breaks=breaks)
dt[Income.Group == "Lower middle income", .N, by=c("Income.Group", "quantileGDP")]
url <- https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv""
""
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
file <- download.file(url)
file <- download.file(url,destfile = "./dest.csv")
read.csv("./dest.csv",he)
?read.csv
read.csv("./dest.csv",header=TRUE)
data <- read.csv("./dest.csv",header=TRUE)
strsplit(data$wgtp)
strsplit(names(data))
?strsplit
strsplit(names(data),"wgtp")
strsplit(names(data),"wgtp")[123]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
f <- file.path(getwd(), "GDP.csv")
download.file(url, f)
dtGDP <- data.table(read.csv(f, skip = 4, nrows = 215, stringsAsFactors = FALSE))
packages <- c("data.table", "quantmod")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
dtGDP <- data.table(read.csv(f, skip = 4, nrows = 215, stringsAsFactors = FALSE))
summary(dtGDP)
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
summary(dtGDP)
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP",
"Long.Name", "gdp"))
gdp <- as.numeric(gsub(",", "", dtGDP$gdp))
gdp
mean(gdp, na.rm = TRUE)
library(quantmod)
install.packages("quantmod")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
summary(sampleTimes)
year(sampleTimes)
yr<-year(sampleTimes)
table(year(sampleTimes), weekdays(sampleTimes))
addmargins(table(year(sampleTimes), weekdays(sampleTimes)))
library(dplyr)
x_train <- read.table("./data/UCI HAR Dataset/train/X_train.txt")
setwd("/home/gareth/courses/data/Week4")
x_train <- read.table("./data/UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./data/UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./data/UCI HAR Dataset/train/subject_train.txt")
x_test <- read.table("./data/UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./data/UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./data/UCI HAR Dataset/test/subject_test.txt")
features <- read.table('./data/UCI HAR Dataset/features.txt')
activityLabels = read.table('./data/UCI HAR Dataset/activity_labels.txt')
features
features[,2]
x_train
colnames(x_train) <- features[,2]
str(y_train)
colnames(y_train) <-"activityId"
subject_train
colnames(subject_train) <- "subjectId"
colnames(x_test) <- features[,2]
colnames(y_test) <- "activityId"
colnames(subject_test) <- "subjectId"
activityLabels
colnames(activityLabels) <- c('activityId','activityType')
mrg_train <- cbind(y_train, subject_train, x_train)
mrg_train
str(mrg_train)
mrg_test <- cbind(y_test, subject_test, x_test)
rbind(mrg_train,mrg_test)
total_data <- rbind(mrg_train,mrg_test)
names(total_data)
names(total_data)<-gsub("^t", "time", names(total_data))
names(total_data)<-gsub("^f", "frequency", names(total_data))
names(total_data)<-gsub("Acc", "Accelerometer", names(total_data))
names(total_data)<-gsub("Gyro", "Gyroscope", names(total_data))
names(total_data)<-gsub("Mag", "Magnitude", names(total_data))
names(total_data)<-gsub("BodyBody", "Body", names(total_data))
colNames <- colnames(total_data)
mean_and_std <- (grepl("activityId" , colNames) |
grepl("subjectId" , colNames) |
grepl("mean.." , colNames) |
grepl("std.." , colNames)
)
mean_and_std
setForMeanAndStd <- setAllInOne[ , mean_and_std == TRUE]
setForMeanAndStd <- total_data[ , mean_and_std == TRUE]#
setForMeanAndStd
setWithActivityNames <- merge(setForMeanAndStd, activityLabels,
by='activityId',
all.x=TRUE)
secTidySet <- aggregate(. ~subjectId + activityId, setWithActivityNames, mean)
secTidySet <- secTidySet[order(secTidySet$subjectId, secTidySet$activityId),]
write.table(secTidySet, "tidy.txt", row.name=FALSE)
names(total_data)
